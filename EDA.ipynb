{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Exploratory Data Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-01T02:30:53.390860Z","iopub.status.busy":"2024-11-01T02:30:53.390335Z","iopub.status.idle":"2024-11-01T02:30:53.398200Z","shell.execute_reply":"2024-11-01T02:30:53.396677Z","shell.execute_reply.started":"2024-11-01T02:30:53.390813Z"},"trusted":true},"outputs":[],"source":["# python\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import cv2  # for image processing\n","from PIL import Image\n","import os\n","\n","# Tensorflow\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from sklearn.model_selection import train_test_split\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-01T02:30:53.401449Z","iopub.status.busy":"2024-11-01T02:30:53.400893Z","iopub.status.idle":"2024-11-01T02:30:53.423194Z","shell.execute_reply":"2024-11-01T02:30:53.422007Z","shell.execute_reply.started":"2024-11-01T02:30:53.401381Z"},"trusted":true},"outputs":[],"source":["healthy_filepath = \"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/Healthy\"\n","unhealthy_filepath = \"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/Brain Tumor\"\n","\n","healthy_count = len(os.listdir(healthy_filepath))\n","unhealthy_count = len(os.listdir(unhealthy_filepath))\n","\n","print(f\"Healthy Images: {healthy_count}, Unhealthy Images: {unhealthy_count}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Load Images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-01T02:30:53.425539Z","iopub.status.busy":"2024-11-01T02:30:53.425162Z","iopub.status.idle":"2024-11-01T02:30:53.433071Z","shell.execute_reply":"2024-11-01T02:30:53.431866Z","shell.execute_reply.started":"2024-11-01T02:30:53.425500Z"},"trusted":true},"outputs":[],"source":["# standardize all of the images\n","def load_images_from_folder(folder, label, image_size=(128, 128)):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder):\n","        filepath = os.path.join(folder, filename)\n","        try: \n","            img = cv2.imread(filepath)\n","            if img is not None: # if openCV can't read the image try with PIL\n","                img = Image.open(filepath)\n","                img = img.convert(\"RGB\") # convert to RGB in case of grayscale or RGBA\n","                img = np.array(img)\n","\n","            img = cv2.resize(img, image_size)\n","            images.append(img)\n","            labels.append(label)\n","        \n","        except Exception as e:\n","            print(f\"Error loading {filename}: {e}\")\n","            continue  # Skip unreadable images\n","            \n","    return images, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-01T02:30:53.435121Z","iopub.status.busy":"2024-11-01T02:30:53.434659Z","iopub.status.idle":"2024-11-01T02:31:13.753508Z","shell.execute_reply":"2024-11-01T02:31:13.752538Z","shell.execute_reply.started":"2024-11-01T02:30:53.435081Z"},"trusted":true},"outputs":[],"source":["# create arrays for images and labels\n","healthy_images, healthy_labels = load_images_from_folder(healthy_filepath, label = 0)\n","unhealthy_images, unhealthy_labels = load_images_from_folder(unhealthy_filepath, label = 1)"]},{"cell_type":"markdown","metadata":{},"source":["# Image Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-01T02:31:13.757176Z","iopub.status.busy":"2024-11-01T02:31:13.756817Z","iopub.status.idle":"2024-11-01T02:31:14.647034Z","shell.execute_reply":"2024-11-01T02:31:14.645847Z","shell.execute_reply.started":"2024-11-01T02:31:13.757140Z"},"trusted":true},"outputs":[],"source":["X = np.array(healthy_images + unhealthy_images) / 255.0\n","y = np.array(healthy_labels + unhealthy_labels)"]},{"cell_type":"markdown","metadata":{},"source":["**X explained:**\n","    This helps normalize the pixel values from their original range of [0, 255] to [0,1]. Normalizing helps the model learn more efficiently and can lead to better training results since most neural networks work better with normalized data. \n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-01T02:31:14.648829Z","iopub.status.busy":"2024-11-01T02:31:14.648435Z","iopub.status.idle":"2024-11-01T02:31:14.654093Z","shell.execute_reply":"2024-11-01T02:31:14.652900Z","shell.execute_reply.started":"2024-11-01T02:31:14.648790Z"},"trusted":true},"outputs":[],"source":["# Data Augmentation\n","data_gen = ImageDataGenerator(\n","    rotation_range=5,      # Smaller rotation range\n","    zoom_range=0.1,        # Small zoom to avoid losing details\n","    width_shift_range=0.05, # Small shifts to keep important features within the frame\n","    height_shift_range=0.05,\n","    fill_mode=\"nearest\"\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["**Data Augmentation:** Is meant to help prevent overfitting. \n","* Rotation Range: randomly rotates images up to 20 degress which helps the model gereralize to slightly rotated images.\n","* Zoom Range: randomly zooms in or out on images by up to 15% which helps the model learn to recognize images at different scales.\n","* Width Shift Range and Height Shift Range: Randomly shifts images horizontally and vertically by up to 20%. This helps the model generalize slightly to images that may not be perfectly centered.\n","* Shear Range: Shear transformation means essentially \"slanting\" the image by up to 15% which helps robustness with slight distortions.\n","* Fill Mode: Speicifies how to fill in new pixel values when shifting, zooming, or rotating an image. "]},{"cell_type":"markdown","metadata":{},"source":["# Split Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-01T02:31:14.656089Z","iopub.status.busy":"2024-11-01T02:31:14.655604Z","iopub.status.idle":"2024-11-01T02:31:15.492631Z","shell.execute_reply":"2024-11-01T02:31:15.491504Z","shell.execute_reply.started":"2024-11-01T02:31:14.656038Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","\n","# Separate healthy and unhealthy data based on labels\n","X_healthy = X[y == 0]\n","X_unhealthy = X[y == 1]\n","\n","# Step 1: Training Set - 60% of total data, balanced 50/50 between healthy and unhealthy\n","train_size_per_class = 540  # 540 healthy, 540 unhealthy\n","X_train = np.concatenate((X_healthy[:train_size_per_class], X_unhealthy[:train_size_per_class]))\n","y_train = np.array([0] * train_size_per_class + [1] * train_size_per_class)\n","\n","# Step 2: Validation Set - 30% of total data, with an 80/20 split\n","val_size_healthy = 432  # 80% healthy\n","val_size_unhealthy = 108  # 20% unhealthy\n","X_val = np.concatenate((X_healthy[train_size_per_class:train_size_per_class + val_size_healthy], \n","                        X_unhealthy[train_size_per_class:train_size_per_class + val_size_unhealthy]))\n","y_val = np.array([0] * val_size_healthy + [1] * val_size_unhealthy)\n","\n","# Step 3: Testing Set - 10% of total data, with an 80/20 split\n","test_size_healthy = 144  # 80% healthy\n","test_size_unhealthy = 36  # 20% unhealthy\n","X_test = np.concatenate((X_healthy[train_size_per_class + val_size_healthy:train_size_per_class + val_size_healthy + test_size_healthy], \n","                         X_unhealthy[train_size_per_class + val_size_unhealthy:train_size_per_class + val_size_unhealthy + test_size_unhealthy]))\n","y_test = np.array([0] * test_size_healthy + [1] * test_size_unhealthy)\n","\n","# Verification\n","print(\"Training set:\", len(X_train), len(y_train))  # Expected: 1080\n","print(\"Validation set:\", len(X_val), len(y_val))    # Expected: 540\n","print(\"Testing set:\", len(X_test), len(y_test))      # Expected: 180\n"]},{"cell_type":"markdown","metadata":{},"source":["**Training Set (2760 Images):**\n","* We select the first 1380 healthy and the first 1380 unhealthy images to ensure a 50/50 split.\n","\n","**Validation Set (1380 Images):**\n","* We select the next 1104 healthy images and 276 unhealthy images to achieve an 80/20 split.\n","\n","**Testing Set (460 Images):**\n","* Finally, we select the next 368 healthy images and 92 unhealthy images to meet the 80/20 split."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1343913,"sourceId":2236708,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
